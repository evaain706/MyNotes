
## 자기소개/관점 관련

1. “동작을 넘어 경험과 성능까지 바라보는 개발자라고 소개하셨는데, 본인이 생각하는 ‘좋은 프론트엔드 개발자’의 기준을 구체적으로 설명해 주실 수 있을까요?”
    
    - 꼬리질문: “이 기준을 본인의 최근 프로젝트에서 어떻게 실천했는지 한 가지 사례만 말씀해 주세요.”​
        
2. “화면 구현에서 끝나지 않고 API 명세를 파악하고 데이터를 어떻게 처리할지 고민한다고 하셨는데, 실제로 API 설계나 응답 구조에 의견을 내본 경험이 있나요?”
    
    - 꼬리질문: “그때 백엔드와 어떤 식으로 의견을 조율했고, 최종적으로 어떤 형태로 바뀌었는지 말씀해 주세요.”
        
3. “Lighthouse나 자동 검사 도구를 활용해 성능을 점검한다고 하셨는데, 본인이 직접 성능 지표를 개선해 본 경험을 말씀해 주세요.”
    
    - 꼬리질문: “그 지표를 선택한 이유와, 그 개선이 실제 사용자 경험에 어떤 영향을 줬다고 판단하셨는지 궁금합니다.”​
        
4. “팀 프로젝트를 통해 협업 능력을 키웠다고 하셨는데, 가장 어려웠던 커뮤니케이션 이슈는 무엇이었고 어떻게 해결하셨나요?”​
    
    - 꼬리질문: “그 경험을 통해 지금은 협업 시 어떤 방식으로 이슈를 정리하고 공유하려고 하나요?”
        
5. “현재 개인 프로젝트를 통해 프론트엔드에 국한되지 않고 시스템 전반을 보려고 노력 중이라고 하셨는데, 시스템을 볼 때 특히 어떤 부분을 중점적으로 보나요?”
    
    - 꼬리질문: “이 시야 확장이 실제로 어떤 기술적 선택(예: API 설계, DB 스키마 고려 등)에 영향을 준 사례가 있을까요?”​
        

## FRONTQUIZ (개인 AI 퀴즈 플랫폼)

6. “FRONTQUIZ 프로젝트를 진행하게 된 계기와, 이 프로젝트의 핵심 목표를 소개해 주세요.”[]​
    
    - 꼬리질문: “이 프로젝트로 면접관에게 어떤 역량을 가장 보여주고 싶으신가요?”[
        
7. “LLM API 기반 퀴즈 생성 시스템에서, 프롬프트 엔지니어링을 어떻게 설계하셨는지 구조를 설명해 주실 수 있을까요?”​
    
    - 꼬리질문: “LLM 응답이 기대와 다르게 왔을 때 어떤 식으로 프롬프트를 수정하거나 로직을 보완하셨나요?”[​
        
8. “텍스트를 일관된 JSON 스키마로 응답받도록 설계했다고 하셨는데, 실제로 어떤 필드 구조로 정의했고, 유효성 검증은 어디에서 어떻게 처리했나요?”
    
    - 꼬리질문: “LLM에서 JSON이 깨져 들어오는 경우에는 어떤 예외 처리 전략을 사용했는지 구체적으로 말씀해 주세요.”​
        
9. “퀴즈 생성/채점 로직에서 클라이언트와 서버의 역할은 어떻게 나누셨나요? 예를 들어, 정답 판단이나 점수 계산은 어디에서 수행되나요?”​
    
    - 꼬리질문: “이 역할 분리 방식이 보안이나 유지보수 관점에서 어떤 장단점이 있다고 보시나요?”​
        
10. “Skeleton UI, Fallback UI, ErrorBoundary를 사용해 UX를 개선했다고 하셨는데, 각각을 어떤 기준으로 적용하셨는지 화면 단위로 설명해 주세요.”
    
    - 꼬리질문: “ErrorBoundary로 처리하기보다는 컴포넌트 레벨 조건부 렌더링으로 처리하는 것이 나은 상황은 어떤 경우라고 생각하시나요?”​
        
11. “Lighthouse 기준 페이지 평균 CLS 0.027, FCP 0.5초를 달성했다고 하셨는데, 초기에는 수치가 어느 정도였고, 어떤 작업을 통해 개선하셨나요?”
    
    - 꼬리질문: “이 수치들이 실제 사용자의 체감과 다르게 느껴질 수 있는 상황은 언제라고 생각하시나요?”​
        
12. “퀴즈 페이지에서 LLM API 에러나 파싱 에러 시 Fallback UI를 제공한다고 하셨는데, 사용자 입장에서 혼란을 줄이기 위해 어떤 메시지와 액션을 제공하고 있나요?
    
    - 꼬리질문: “이 상황에서 단순 재시도 외에 UX를 더 개선하기 위해 고려해본 다른 방안이 있을까요?”​
        
13. “TanStack Query의 useQuery를 사용하는 컴포넌트마다 isError 상태일 때 공통 Fallback 컴포넌트를 사용하셨다고 했는데, 에러 종류별로 다른 처리가 필요해진다면 구조를 어떻게 바꾸실 계획인가요?”​
    
    - 꼬리질문: “에러 처리 로직을 한 곳에 모을 때의 장점과, 과도하게 추상화했을 때의 단점은 무엇이라고 보나요?”
        

  14. 프로젝트 계기 및 핵심 목표
   * 계기: 프론트엔드 학습 과정에서 텍스트 위주의 학습보다는 퀴즈 형식을 통해 재미있게 지식을 점검하고 부족한 부분을 파악할 수 있는 플랫폼의 필요성을 느꼈습니다.
   * 핵심 목표: LLM(Meta Llama)을 활용하여 실시간으로 최신 프론트엔드 트렌드가 반영된 맞춤형 퀴즈를 생성하고, 상세한 해설과 학습 통계를 제공하여 사용자의 성장을 돕는 것입니다.
   * 보여주고 싶은 역량: AI API를 프론트엔드 환경에 통합하는 능력과, 복잡한 비동기 로직 및 에러 상황에서도 사용자 경험(UX)을 유지하기 위한 기술적 고민(ErrorBoundary, Skeleton UI, 성능 최적화 등)을 강조하고 싶습니다.


  7. LLM API 프롬프트 엔지니어링 설계
   * 구조: 백엔드에서 topic과 level을 매개변수로 받아 시스템 프롬프트를 구성합니다. "너는 프론트엔드 전문가이다"라는 Role-play를 설정하고, 난이도별 문제 유형(개념, 코드 분석, 트러블슈팅 등)을 정의하여 프롬프트를 전달합니다.
   * 보안 및 보완: 응답이 기대와 다를 경우를 대비해 온도(Temperature) 조절을 통해 일관성을 확보하고, 프론트엔드에서는 onRetry 로직을 포함한 QuizErrorFallback을 배치하여 사용자에게 자연스러운 재시도를 유도하도록 설계했습니다.


  8. JSON 스키마 설계 및 유효성 검증
   * 구조: question (string), options (객체: { "1": "선택지1", ... }), answer (string: 정답 키값) 필드로 정의했습니다.
   * 검증: 프론트엔드에서는 TypeScript 인터페이스(Quiz)를 사용하여 데이터 구조를 명시하고, 렌더링 시 데이터 존재 여부를 체크(!markdownContent)하여 방어적으로 코딩했습니다.
   * 예외 처리: JSON이 깨지거나 형식이 다를 경우 JSON.parse 에러가 발생하며, 이를 컴포넌트 레벨의 ErrorBoundary가 포착하여 사용자에게 "퀴즈 불러오기 실패"라는 안내와 함께 재시도 버튼을 노출하는 전략을 사용했습니다.


  9. 클라이언트와 서버의 역할 분리
   * 역할 분리:
       * 서버: LLM을 통한 퀴즈 생성, 정답 여부 판단 및 해설 생성, 통계 데이터 관리(보안 및 로직 보호).
       * 클라이언트: 퀴즈 요청 옵션 관리(Zustand), 퀴즈 렌더링, 사용자 응답 수집, 결과 표시 및 캐시 관리(TanStack Query).
   * 장단점:
       * 장점: 정답 로직을 서버에 두어 클라이언트 소스 코드를 통한 정답 유출을 방지하고, 복잡한 연산을 서버에 위임하여 클라이언트 부하를 줄였습니다.
       * 단점: 매 동작마다 API 호출이 필요하므로 네트워크 지연이 발생할 수 있으나, 이를 Skeleton UI와 Spinner로 보완했습니다.


  10. Skeleton UI, Fallback UI, ErrorBoundary 적용 기준
   * Skeleton UI: 데이터 로딩 중 레이아웃 시프트를 방지하기 위해 사용합니다. QuestionCard, OptionsCard, PostGrid 등 주요 컨텐츠 영역에 적용하여 "데이터가 곧 로드될 것"이라는 시각적 신호를 줍니다.
   * Fallback UI & ErrorBoundary: 퀴즈 스크린의 핵심 비즈니스 로직(퀴즈 생성/채점)에서 발생하는 예상치 못한 런타임 에러를 격리하기 위해 적용했습니다.
   * 조건부 렌더링 vs ErrorBoundary: 단순한 빈 데이터(null)나 예상 가능한 유효성 검사 결과는 조건부 렌더링으로 처리하고, API 통신 실패나 파싱 에러처럼 전체 컴포넌트 트리를 깨뜨릴 수 있는 심각한 에러는 ErrorBoundary로 선언적으로 처리했습니다.


  11. Lighthouse 성능 개선 (CLS 0.027, FCP 0.5초)
   * 초기 상황: 이미지 로딩 지연 및 폰트 로드 시 레이아웃 흔들림이 있었습니다.
   * 개선 작업:
       * Variable Font(PretendardVariable.woff2) 도입 및 font-display: swap 설정으로 폰트 로딩 속도 및 CLS 개선.
       * Skeleton UI 적용으로 컨텐츠 로드 전후의 레이아웃 시프트 최소화.
       * React.lazy와 Suspense를 활용한 react-markdown 등 무거운 라이브러리 코드 분할.
   * 체감 차이: 지표상으로는 훌륭하나, 서버 API 응답 자체가 느린 경우(LLM 생성 시간) 사용자는 여전히 Skeleton 상태를 오래 보게 되므로, 이를 위해 재치 있는 로딩 메시지를 추가하는 등의 UX 보완이 필요할 수 있습니다.


  12. 에러 발생 시 UX 전략
   * 메시지/액션: "퀴즈 불러오기 실패"와 같은 직관적인 메시지와 함께 다시 시도 버튼을 제공합니다. 커뮤니티 등에서는 메인페이지로 이동 버튼을 추가해 탈출 경로를 보장합니다.
   * 추가 개선 방안: 단순 재시도 외에, 서버 에러 시 미리 준비된 정적 퀴즈 셋을 제공하여 서비스 중단을 막는 'Graceful Degradation' 전략을 고려해 볼 수 있습니다.


  13. TanStack Query 에러 처리 구조
   * 구조 변경 계획: 현재 isError 상태에 따라 공통 ErrorComp를 리턴하고 있습니다. 에러 종류가 다양해진다면 Axios Interceptor를 통해 에러 코드를 분류하고, ErrorComp 내부에서 에러 타입별 분기 처리(예: 401은 로그인 유도, 500은 시스템 점검 안내)를 수행할 계획입니다.     
   * 추상화의 장단점:
       * 장점: 에러 처리 로직의 일관성을 유지하고 중복 코드를 획기적으로 줄일 수 있습니다.
       * 단점: 모든 에러를 한곳에서 처리하려다 보면, 특정 페이지나 컴포넌트에서만 필요한 세밀한 에러 대응(예: 특정 필드만 붉게 표시)이 어려워질 수 있습니다.
## GLOBALNOMAD (예약 플랫폼 팀 프로젝트)

14. “GLOBALNOMAD 프로젝트에서 본인이 담당했던 주요 기능/화면을 중심으로 역할을 설명해 주세요.”​
    
    - 꼬리질문: “그중 가장 기술적으로 어려웠던 부분 한 가지를 선택해 깊게 설명해 주실 수 있을까요?”​
        
15. “Next.js의 API Route를 백엔드 서버와의 프록시로 사용하셨다고 했는데, 이 구조를 선택한 이유와 장점/단점을 설명해 주세요.”​
    
    - 꼬리질문: “만약 BFF(Backend for Frontend)로 확장해야 한다면, 현재 구조에서 어떤 점을 바꾸고 싶으신가요?”[​
        
16. “API Route 단에서 에러 메시지를 재정의했다고 하셨는데, 에러를 어떤 기준으로 분류하고, 프론트에는 어떤 형태로 전달했는지 구체적으로 말씀해 주세요.
    
    - 꼬리질문: “이때 HTTP Status Code 설계는 어떻게 하셨고, 고민됐던 포인트는 무엇인가요?”​
        
17. “예약 가능한 일정을 보여주는 달력 컴포넌트에서 Promise.allSettled로 프리페칭을 구현하셨다고 했는데, all과 allSettled 중 allSettled를 선택한 이유는 무엇인가요?”
    
    - 꼬리질문: “만약 특정 월의 요청이 실패했을 때, UI에서는 어떻게 보여주도록 설계했나요?”​
        
18. “달력을 직접 구현하면서 Day.js를 선택하신 이유와, 그 과정에서 고려했던 다른 대안(예: date-fns, Moment.js 등)이 있었는지 궁금합니다.”​
    
    - 꼬리질문: “번들 사이즈 관점에서 Day.js를 사용할 때 주의해야 할 점은 무엇이라고 생각하나요?”​
        
19. “예약 인터페이스에서 클라이언트 상태(Zustand)와 서버 상태(TanStack Query)를 나누어 관리하셨는데, 두 상태의 경계를 어떻게 정의하셨나요?”​
    
    - 꼬리질문: “이 경계가 애매해지는 사례(예: optimistic update가 필요한 경우)에는 어떻게 설계하실지 생각을 듣고 싶습니다.​
        
20. “Zustand에서 Selector 기반 선택적 구독을 적용하셨다고 했는데, 실제로 어떤 상태를 어떻게 나누고, 리렌더링이 얼마나 줄었는지 체감이 있었나요?”
    
    - 꼬리질문: “Zustand 대신 다른 상태관리 도구를 쓴다면 어떤 것을 고려하시겠고, 그 이유는 무엇인가요?”​
        
21. “예약 버튼 활성/비활성 제어에 유효성 검증 로직을 얹으셨다고 했는데, 유효성 검증을 어디 레이어에서 수행하는 것이 가장 적절하다고 생각하나요? (컴포넌트, 훅, store 등)”
    
    - 꼬리질문: “서버 쪽 유효성 검증과의 중복을 어떻게 바라보고 설계하셨나요?”[​
        
22. “useDeviceSize 커스텀 훅으로 반응형 UI를 구현하셨는데, CSS 미디어쿼리나 Tailwind/Styled-components의 반응형 기능 대신 JS 기반 감지를 사용한 이유가 있나요?”[]​
    
    - 꼬리질문: “JS로 디바이스 크기를 감지할 때 성능이나 이벤트 최적화 측면에서 어떤 점을 유의하셨나요?”[​
        
23. “TanStack Query에서 Query Key Factory 패턴을 적용해 기능 단위로 queryKey를 관리했다고 하셨는데, 실제로 어떤 형태로 key를 정의하고, 이를 통해 얻은 이점은 무엇인가요?”[
    
    - 꼬리질문: “queryKey 설계가 잘못되어 invalidate가 어려워진 경험이 있다면, 어떻게 개선하셨는지도 듣고 싶습니다.​
        
24. “검색에 Debounce(300ms)를 적용하셨는데, 이 값을 결정한 기준과, Debounce가 사용자 경험에 부정적으로 작용할 수 있는 상황은 언제라고 보시나요?”[
    
    - 꼬리질문: “Debounce 외에 API 호출 비용을 줄이기 위해 고려한 다른 전략이 있다면 무엇인가요?”​
        
25. “클라이언트 상태, 서버 상태, 비즈니스 로직을 분리하셨다고 했는데, 이 구조를 코드 레벨에서 어떻게 나누셨는지 디렉터리/레이어 구조를 예로 들어 설명해 주세요.”[[
    
    - 꼬리질문: “이 구조가 팀원들에게 이해되도록 공유할 때 어떤 문서나 규칙을 정하셨나요?”[]​
        

## 공통 기술/CS 및 성능·UX

26. “FRONTQUIZ와 GLOBALNOMAD 모두에서 TanStack Query를 사용하셨는데, useSWR 등 다른 데이터 패칭 라이브러리와 비교했을 때 장단점을 어떻게 보시나요?”[
    
    - 꼬리질문: “앞으로 새 프로젝트를 만든다면, TanStack Query를 다시 선택할지, 다른 도구를 고려할지와 그 이유를 말씀해 주세요.”[​
        
27. “성능 최적화를 고민한다고 하셨는데, 프론트엔드에서 가장 우선순위 높게 보는 성능 지표 2~3개와, 각각을 개선하기 위한 대표적인 방법을 설명해 주세요.”[
    
    - 꼬리질문: “한 화면에서 성능과 UX가 상충될 때, 어떤 기준으로 트레이드오프를 결정하시나요?”[​
        
28. “ErrorBoundary, Fallback UI 등 에러 처리를 중시한다고 하셨는데, 에러 로깅/모니터링 도구(Sentry 등)를 붙인다면 어디에 어떤 정보를 남기고 싶으신가요?”[
    
    - 꼬리질문: “에러 로그가 쌓였을 때, 이를 실제 개선 작업으로 연결하기 위한 프로세스를 어떻게 설계하고 싶으신가요?”​
        
29. “양 프로젝트에서 공통적으로 재사용 가능한 컴포넌트나 훅을 설계한 경험이 있나요? 있다면 그중 하나를 골라 설계 의도와 API를 설명해 주세요.”[​
    
    - 꼬리질문: “그 컴포넌트/훅의 범용성을 더 높이기 위해 개선하고 싶은 부분이 있다면 무엇인가요?”[​
        
30. “등록/수정 폼에서 클라이언트 사이드 유효성 검증 및 유저 피드백을 구현하셨다고 했는데, 어떤 규칙을 util 함수로 분리했고, 어떤 기준으로 공통화하셨는지 설명해 주세요.”​
    
    - 꼬리질문: “폼 유효성 검증을 라이브러리(예: React Hook Form, Zod 등)와 함께 사용한다면 어떤 구조로 가져가고 싶으신가요?”[]​
        

## 협업, 프로세스, 성장

31. “총 4번의 팀 프로젝트를 진행하며 스크럼 형식으로 이슈를 공유했다고 하셨는데, 하루/주 단위로 실제로 어떤 식으로 진행했는지 구체적인 루틴을 설명해 주세요.”[
    
    - 꼬리질문: “스크럼 방식의 장단점을 느끼신 점과, 다음 팀 프로젝트에서는 무엇을 바꾸고 싶은지 말씀해 주세요.”​
        
32. “코드잇 스프린트 과정에서 CI/CD, PWA, 디자인 시스템을 경험하셨다고 했는데, 이 중 하나를 골라 실제로 적용했던 사례를 자세히 설명해 주세요.”​
    
    - 꼬리질문: “그 경험이 이후 개인/팀 프로젝트에 어떤 방식으로 재사용되었나요?”[[
        
33. “협업 과정에서 코드 스타일이나 디렉터리 구조 등 의견이 갈렸던 적이 있다면, 어떻게 합의점을 찾으셨나요?”​
    
    - 꼬리질문: “만약 합의가 잘 안 되었을 때, 본인은 어떤 기준으로 우선순위를 두고 설득하려 하나요?”​
        
34. “최근에 학습한 내용 중, 프론트엔드 개발자로서 ‘이건 꼭 써먹어 보고 싶다’고 느낀 기술이나 개념이 있다면 하나만 소개해 주세요.”​
    
    - 꼬리질문: “그것을 FRONTQUIZ나 GLOBALNOMAD에 적용한다면, 어디에 어떻게 적용해 볼 수 있을까요?”​
        
35. “앞으로 1~2년 안에 어떤 프론트엔드 개발자로 성장하고 싶으신지, 구체적인 기술/역할 관점에서 목표를 말씀해 주세요.”​
    
    - 꼬리질문: “그 목표를 위해 올해 안에 실천해 보고 싶은 구체적인 액션 2~3가지를 말씀해 주세요.”​
        

원하시면, 각 질문별로 “이력서 기반 모범 답변 초안”도 만들어 드릴게요.